#!/usr/bin/env python3
"""
Real-Time Data Fabric AI - Intelligent Trust Scoring & Verification
===================================================================

AI-powered system that:
- Runs trust scoring on live data from multiple sources
- Cross-verifies facts using LLMs and NER models
- Extracts and validates structured data
- Maintains data freshness and accuracy
- Eliminates stale/hallucinated information

Ensures 100% reliable data for automation decisions.
"""

import asyncio
import json
import time
import logging
import hashlib
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import re
import statistics
from collections import defaultdict, deque
import urllib.parse
import urllib.request
import os
import sqlite3

# AI imports with fallbacks
try:
    from transformers import AutoTokenizer, AutoModel, pipeline
    from sentence_transformers import SentenceTransformer
    import numpy as np
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False
    np = None

# LLM provider imports
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

# Built-in fallbacks
from .builtin_ai_processor import BuiltinAIProcessor
from .builtin_data_validation import BaseValidator

logger = logging.getLogger(__name__)

class DataSource(Enum):
    """Types of data sources"""
    WEB_API = "web_api"
    DATABASE = "database"
    WEB_SCRAPING = "web_scraping"
    FILE_SYSTEM = "file_system"
    LIVE_FEED = "live_feed"
    USER_INPUT = "user_input"
    CACHED_DATA = "cached_data"

class TrustLevel(Enum):
    """Trust levels for data"""
    VERIFIED = "verified"        # 90-100% confidence
    TRUSTED = "trusted"          # 70-89% confidence
    QUESTIONABLE = "questionable" # 50-69% confidence
    UNTRUSTED = "untrusted"      # 0-49% confidence

class DataType(Enum):
    """Types of data being processed"""
    TEXT = "text"
    NUMBER = "number"
    DATE = "date"
    URL = "url"
    EMAIL = "email"
    PHONE = "phone"
    ADDRESS = "address"
    ENTITY = "entity"
    STRUCTURED = "structured"

@dataclass
class DataPoint:
    """Individual piece of data with metadata"""
    data_id: str
    value: Any
    data_type: DataType
    source: DataSource
    source_url: Optional[str]
    timestamp: float
    confidence: float
    trust_level: TrustLevel
    verification_count: int
    conflicting_values: List[Any]
    metadata: Dict[str, Any]

@dataclass
class VerificationResult:
    """Result of data verification"""
    data_id: str
    is_verified: bool
    confidence_score: float
    trust_level: TrustLevel
    verification_method: str
    supporting_sources: List[str]
    conflicting_sources: List[str]
    extracted_facts: List[Dict[str, Any]]
    processing_time_ms: float

@dataclass
class CrossReference:
    """Cross-reference between data points"""
    primary_data_id: str
    reference_data_id: str
    similarity_score: float
    relationship_type: str
    confidence: float

class NERProcessor:
    """Named Entity Recognition processor with AI fallbacks"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.ner_pipeline = None
        self.fallback_processor = BuiltinAIProcessor()
        self._initialize_models()
    
    def _initialize_models(self):
        """Initialize NER models"""
        if AI_AVAILABLE:
            try:
                # Use transformers NER pipeline
                self.ner_pipeline = pipeline("ner", 
                                            model="dbmdz/bert-large-cased-finetuned-conll03-english",
                                            aggregation_strategy="simple")
                logger.info("‚úÖ NER pipeline loaded")
            except Exception as e:
                logger.warning(f"NER model loading failed: {e}")
    
    def extract_entities(self, text: str) -> List[Dict[str, Any]]:
        """Extract named entities from text"""
        if not text or not text.strip():
            return []
        
        if self.ner_pipeline:
            try:
                # Use AI NER
                entities = self.ner_pipeline(text)
                
                # Convert to standard format
                formatted_entities = []
                for entity in entities:
                    formatted_entities.append({
                        'text': entity['word'],
                        'label': entity['entity_group'],
                        'confidence': entity['score'],
                        'start': entity.get('start', 0),
                        'end': entity.get('end', 0)
                    })
                
                return formatted_entities
                
            except Exception as e:
                logger.warning(f"AI NER failed: {e}")
        
        # Fallback to rule-based NER
        return self._fallback_entity_extraction(text)
    
    def _fallback_entity_extraction(self, text: str) -> List[Dict[str, Any]]:
        """Fallback rule-based entity extraction"""
        entities = []
        
        # Email pattern
        email_pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        for match in re.finditer(email_pattern, text):
            entities.append({
                'text': match.group(),
                'label': 'EMAIL',
                'confidence': 0.9,
                'start': match.start(),
                'end': match.end()
            })
        
        # Phone pattern
        phone_pattern = r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b'
        for match in re.finditer(phone_pattern, text):
            entities.append({
                'text': match.group(),
                'label': 'PHONE',
                'confidence': 0.8,
                'start': match.start(),
                'end': match.end()
            })
        
        # URL pattern
        url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
        for match in re.finditer(url_pattern, text):
            entities.append({
                'text': match.group(),
                'label': 'URL',
                'confidence': 0.95,
                'start': match.start(),
                'end': match.end()
            })
        
        # Date patterns (simplified)
        date_patterns = [
            r'\b\d{1,2}[/-]\d{1,2}[/-]\d{4}\b',  # MM/DD/YYYY or MM-DD-YYYY
            r'\b\d{4}[/-]\d{1,2}[/-]\d{1,2}\b',  # YYYY/MM/DD or YYYY-MM-DD
        ]
        
        for pattern in date_patterns:
            for match in re.finditer(pattern, text):
                entities.append({
                    'text': match.group(),
                    'label': 'DATE',
                    'confidence': 0.7,
                    'start': match.start(),
                    'end': match.end()
                })
        
        return entities

class FactVerifierAI:
    """AI-powered fact verification using LLMs"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.llm_clients = {}
        self.text_model = None
        self.fallback_processor = BuiltinAIProcessor()
        self._initialize_clients()
    
    def _initialize_clients(self):
        """Initialize LLM clients for fact verification"""
        # Initialize text similarity model
        if AI_AVAILABLE:
            try:
                self.text_model = SentenceTransformer('all-MiniLM-L6-v2')
                logger.info("‚úÖ Text similarity model loaded")
            except Exception as e:
                logger.warning(f"Text model loading failed: {e}")
        
        # Initialize LLM clients
        if OPENAI_AVAILABLE and self.config.get('openai_api_key'):
            try:
                self.llm_clients['openai'] = openai.AsyncOpenAI(
                    api_key=self.config['openai_api_key']
                )
                logger.info("‚úÖ OpenAI client initialized for fact verification")
            except Exception as e:
                logger.warning(f"OpenAI initialization failed: {e}")
        
        if ANTHROPIC_AVAILABLE and self.config.get('anthropic_api_key'):
            try:
                self.llm_clients['anthropic'] = anthropic.AsyncAnthropic(
                    api_key=self.config['anthropic_api_key']
                )
                logger.info("‚úÖ Anthropic client initialized for fact verification")
            except Exception as e:
                logger.warning(f"Anthropic initialization failed: {e}")
    
    async def verify_fact(self, claim: str, context: Dict[str, Any], 
                         supporting_data: List[str]) -> Dict[str, Any]:
        """Verify a factual claim using AI"""
        start_time = time.time()
        
        # Try AI verification first
        if self.llm_clients:
            for provider, client in self.llm_clients.items():
                try:
                    result = await self._verify_with_llm(provider, client, claim, context, supporting_data)
                    result['processing_time_ms'] = (time.time() - start_time) * 1000
                    result['used_ai'] = True
                    result['provider'] = provider
                    return result
                except Exception as e:
                    logger.warning(f"LLM verification failed with {provider}: {e}")
                    continue
        
        # Fallback to rule-based verification
        result = self._fallback_fact_verification(claim, context, supporting_data)
        result['processing_time_ms'] = (time.time() - start_time) * 1000
        result['used_ai'] = False
        result['provider'] = 'fallback'
        return result
    
    async def _verify_with_llm(self, provider: str, client: Any, claim: str, 
                              context: Dict[str, Any], supporting_data: List[str]) -> Dict[str, Any]:
        """Verify fact using specific LLM provider"""
        
        # Build verification prompt
        prompt = self._build_verification_prompt(claim, context, supporting_data)
        
        if provider == 'openai':
            response = await client.chat.completions.create(
                model=self.config.get('openai_model', 'gpt-3.5-turbo'),
                messages=[
                    {"role": "system", "content": "You are a fact-checking expert. Analyze claims and provide confidence scores."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=500
            )
            
            return self._parse_llm_response(response.choices[0].message.content)
            
        elif provider == 'anthropic':
            response = await client.messages.create(
                model=self.config.get('anthropic_model', 'claude-3-haiku-20240307'),
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=500
            )
            
            return self._parse_llm_response(response.content[0].text)
    
    def _build_verification_prompt(self, claim: str, context: Dict[str, Any], 
                                  supporting_data: List[str]) -> str:
        """Build prompt for fact verification"""
        supporting_text = "\n".join(supporting_data[:5])  # Limit to 5 sources
        
        return f"""
Please verify the following claim and provide a confidence score:

CLAIM: {claim}

CONTEXT: {json.dumps(context, indent=2)}

SUPPORTING DATA:
{supporting_text}

Please respond in JSON format:
{{
    "is_verified": true/false,
    "confidence_score": 0.0-1.0,
    "reasoning": "explanation",
    "supporting_evidence": ["evidence1", "evidence2"],
    "contradicting_evidence": ["contradiction1"],
    "trust_level": "verified/trusted/questionable/untrusted"
}}
"""
    
    def _parse_llm_response(self, response_text: str) -> Dict[str, Any]:
        """Parse LLM response into structured result"""
        try:
            # Try to extract JSON from response
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                
                # Validate and normalize result
                return {
                    'is_verified': result.get('is_verified', False),
                    'confidence_score': float(result.get('confidence_score', 0.5)),
                    'reasoning': result.get('reasoning', ''),
                    'supporting_evidence': result.get('supporting_evidence', []),
                    'contradicting_evidence': result.get('contradicting_evidence', []),
                    'trust_level': result.get('trust_level', 'questionable')
                }
        except Exception as e:
            logger.warning(f"Failed to parse LLM response: {e}")
        
        # Fallback parsing
        confidence = 0.5
        if 'high confidence' in response_text.lower() or 'verified' in response_text.lower():
            confidence = 0.9
        elif 'low confidence' in response_text.lower() or 'uncertain' in response_text.lower():
            confidence = 0.3
        
        return {
            'is_verified': confidence > 0.7,
            'confidence_score': confidence,
            'reasoning': response_text[:200],
            'supporting_evidence': [],
            'contradicting_evidence': [],
            'trust_level': 'trusted' if confidence > 0.7 else 'questionable'
        }
    
    def _fallback_fact_verification(self, claim: str, context: Dict[str, Any], 
                                   supporting_data: List[str]) -> Dict[str, Any]:
        """Fallback rule-based fact verification"""
        # Simple heuristic-based verification
        confidence = 0.5
        supporting_count = 0
        contradicting_count = 0
        
        claim_lower = claim.lower()
        
        # Check supporting data
        for data in supporting_data:
            # Coerce to string for robust matching
            try:
                data_str = data if isinstance(data, str) else json.dumps(data, ensure_ascii=False)
            except Exception:
                data_str = str(data)
            data_lower = data_str.lower()
            
            # Simple keyword matching
            if any(word in data_lower for word in claim_lower.split() if len(word) > 3):
                supporting_count += 1
            
            # Look for contradicting words
            if any(word in data_lower for word in ['not', 'false', 'incorrect', 'wrong']):
                contradicting_count += 1
        
        # Calculate confidence based on support
        if supporting_count > 0:
            confidence = min(0.9, 0.5 + (supporting_count * 0.1))
        
        if contradicting_count > 0:
            confidence = max(0.1, confidence - (contradicting_count * 0.2))
        
        # Determine trust level
        if confidence >= 0.9:
            trust_level = 'verified'
        elif confidence >= 0.7:
            trust_level = 'trusted'
        elif confidence >= 0.5:
            trust_level = 'questionable'
        else:
            trust_level = 'untrusted'
        
        return {
            'is_verified': confidence > 0.7,
            'confidence_score': confidence,
            'reasoning': f"Rule-based verification: {supporting_count} supporting, {contradicting_count} contradicting",
            'supporting_evidence': supporting_data[:supporting_count],
            'contradicting_evidence': [],
            'trust_level': trust_level
        }

class DataCollector:
    """Collects data from multiple sources"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.source_configs = config.get('data_sources', {})
    
    async def collect_from_source(self, source_type: DataSource, query: str, 
                                 source_config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Collect data from a specific source"""
        try:
            if source_type == DataSource.WEB_API:
                return await self._collect_from_api(query, source_config)
            elif source_type == DataSource.WEB_SCRAPING:
                return await self._collect_from_web(query, source_config)
            elif source_type == DataSource.DATABASE:
                return await self._collect_from_database(query, source_config)
            elif source_type == DataSource.FILE_SYSTEM:
                return await self._collect_from_files(query, source_config)
            else:
                logger.warning(f"Unsupported source type: {source_type}")
                return []
        except Exception as e:
            logger.error(f"Failed to collect from {source_type}: {e}")
            return []
    
    async def _collect_from_api(self, query: str, config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Collect data from web API (real HTTP call)"""
        api_url = config.get('url', '').strip()
        if not api_url:
            return []
        
        # Build URL with query if needed
        if '{query}' in api_url:
            full_url = api_url.replace('{query}', urllib.parse.quote_plus(query))
        else:
            params = config.get('params', {})
            if query and 'q' not in params:
                params['q'] = query
            if params:
                sep = '&' if ('?' in api_url) else '?'
                full_url = f"{api_url}{sep}{urllib.parse.urlencode(params)}"
            else:
                full_url = api_url
        
        headers = config.get('headers', {})
        timeout_ms = int(config.get('timeout_ms', 8000))
        req = urllib.request.Request(full_url, headers=headers)
        try:
            with urllib.request.urlopen(req, timeout=timeout_ms / 1000.0) as resp:
                content_type = resp.headers.get('Content-Type', '')
                raw = resp.read()
                value: Any
                try:
                    if 'json' in content_type or raw.strip().startswith(b'{') or raw.strip().startswith(b'['):
                        value = json.loads(raw.decode('utf-8', errors='ignore'))
                    else:
                        # Return textual content snippet
                        text = raw.decode('utf-8', errors='ignore')
                        value = text[:2000]
                except Exception:
                    value = raw[:2048]
                return [{
                    'value': value,
                    'source_url': full_url,
                    'confidence': float(config.get('default_confidence', 0.8)),
                    'timestamp': time.time()
                }]
        except Exception as e:
            logger.error(f"API collection error from {full_url}: {e}")
            return []

    async def _collect_from_web(self, query: str, config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Collect data from web pages (real HTTP fetch)"""
        base_url = config.get('base_url', '').strip()
        if not base_url:
            return []
        
        # Construct a simple search URL if supported, otherwise fetch base URL
        url = base_url
        if '{query}' in base_url:
            url = base_url.replace('{query}', urllib.parse.quote_plus(query))
        elif '?' not in base_url:
            url = f"{base_url}?q={urllib.parse.quote_plus(query)}"
        
        headers = config.get('headers', {})
        timeout_ms = int(config.get('timeout_ms', 8000))
        req = urllib.request.Request(url, headers=headers)
        try:
            with urllib.request.urlopen(req, timeout=timeout_ms / 1000.0) as resp:
                html = resp.read().decode('utf-8', errors='ignore')
                # Extract title and a small snippet
                title_match = re.search(r"<title>(.*?)</title>", html, re.IGNORECASE | re.DOTALL)
                title = title_match.group(1).strip() if title_match else ''
                snippet = re.sub(r"<[^>]+>", " ", html)
                snippet = re.sub(r"\s+", " ", snippet).strip()[:500]
                return [{
                    'value': {'title': title, 'snippet': snippet},
                    'source_url': url,
                    'confidence': float(config.get('default_confidence', 0.6)),
                    'timestamp': time.time()
                }]
        except Exception as e:
            logger.error(f"Web collection error from {url}: {e}")
            return []

    async def _collect_from_database(self, query: str, config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Collect data from SQLite database (real query)"""
        db_path = config.get('sqlite_path')
        table = config.get('table')
        column = config.get('column')
        if not (db_path and table and column):
            return []
        try:
            rows: List[Dict[str, Any]] = []
            conn = sqlite3.connect(db_path)
            try:
                conn.row_factory = sqlite3.Row
                cur = conn.cursor()
                cur.execute(f"SELECT {column} AS value FROM {table} WHERE {column} LIKE ? LIMIT 20", (f"%{query}%",))
                for r in cur.fetchall():
                    rows.append({
                        'value': r['value'],
                        'source_url': f"sqlite://{db_path}:{table}.{column}",
                        'confidence': 0.95,
                        'timestamp': time.time()
                    })
            finally:
                conn.close()
            return rows
        except Exception as e:
            logger.error(f"Database collection error: {e}")
            return []

    async def _collect_from_files(self, query: str, config: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Collect data from filesystem (real file scan)"""
        base_path = config.get('base_path') or '.'
        exts = set(config.get('exts', ['.txt', '.md', '.log']))
        max_files = int(config.get('max_files', 50))
        max_bytes = int(config.get('max_bytes', 1024 * 1024))
        results: List[Dict[str, Any]] = []
        try:
            count = 0
            for root, _, files in os.walk(base_path):
                for name in files:
                    if count >= max_files:
                        break
                    if exts and not any(name.lower().endswith(ext) for ext in exts):
                        continue
                    path = os.path.join(root, name)
                    try:
                        with open(path, 'rb') as f:
                            data = f.read(max_bytes)
                        text = data.decode('utf-8', errors='ignore')
                        if query.lower() in text.lower():
                            # capture a small snippet around first occurrence
                            idx = text.lower().find(query.lower())
                            start = max(0, idx - 120)
                            end = min(len(text), idx + 120)
                            snippet = text[start:end].replace('\n', ' ')
                            results.append({
                                'value': {'file': path, 'snippet': snippet},
                                'source_url': f"file://{path}",
                                'confidence': 0.7,
                                'timestamp': time.time()
                            })
                            count += 1
                    except Exception:
                        continue
            return results
        except Exception as e:
            logger.error(f"Filesystem collection error: {e}")
            return []

class RealTimeDataFabricAI:
    """Main real-time data fabric with AI-powered trust scoring"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.ner_processor = NERProcessor(config)
        self.fact_verifier = FactVerifierAI(config)
        self.data_collector = DataCollector(config)
        
        # Data storage
        self.data_points: Dict[str, DataPoint] = {}
        self.cross_references: List[CrossReference] = []
        self.verification_cache: Dict[str, VerificationResult] = {}
        
        # Performance tracking
        self.stats = {
            'total_data_points': 0,
            'verified_data_points': 0,
            'trust_distribution': defaultdict(int),
            'verification_time_avg': 0.0,
            'cache_hit_rate': 0.0
        }
        
        # Real-time processing queue
        self.processing_queue = None
        self.is_processing = False
        self._background_task = None
    
    def _ensure_background_processor(self):
        """Ensure background processor is running"""
        if self.processing_queue is None:
            try:
                self.processing_queue = asyncio.Queue()
                if self._background_task is None or self._background_task.done():
                    self._background_task = asyncio.create_task(self._background_processor())
            except RuntimeError:
                # No event loop running, background processing will be disabled
                pass
    
    async def ingest_data(self, value: Any, data_type: DataType, source: DataSource,
                         source_url: Optional[str] = None, metadata: Optional[Dict[str, Any]] = None) -> str:
        """Ingest new data point for processing"""
        self._ensure_background_processor()
        data_id = hashlib.md5(f"{value}_{source}_{time.time()}".encode()).hexdigest()
        
        data_point = DataPoint(
            data_id=data_id,
            value=value,
            data_type=data_type,
            source=source,
            source_url=source_url,
            timestamp=time.time(),
            confidence=0.5,  # Initial confidence
            trust_level=TrustLevel.QUESTIONABLE,
            verification_count=0,
            conflicting_values=[],
            metadata=metadata or {}
        )
        
        self.data_points[data_id] = data_point
        self.stats['total_data_points'] += 1
        
        # Queue for verification
        if self.processing_queue:
            await self.processing_queue.put(data_id)
        
        logger.info(f"üì• Ingested data point: {data_id}")
        return data_id
    
    async def verify_data_point(self, data_id: str) -> VerificationResult:
        """Verify a specific data point"""
        if data_id not in self.data_points:
            raise ValueError(f"Data point {data_id} not found")
        
        # Check cache first
        cache_key = f"verify_{data_id}"
        if cache_key in self.verification_cache:
            self.stats['cache_hit_rate'] = (self.stats['cache_hit_rate'] * 0.9) + (1.0 * 0.1)
            return self.verification_cache[cache_key]
        
        data_point = self.data_points[data_id]
        start_time = time.time()
        
        # Collect supporting data from multiple sources
        supporting_data = await self._collect_supporting_data(data_point)
        
        # Extract entities if text data
        extracted_facts = []
        if data_point.data_type == DataType.TEXT:
            entities = self.ner_processor.extract_entities(str(data_point.value))
            extracted_facts = [
                {
                    'entity': entity['text'],
                    'type': entity['label'],
                    'confidence': entity['confidence']
                }
                for entity in entities
            ]
        
        # Verify using AI
        verification = await self.fact_verifier.verify_fact(
            str(data_point.value),
            data_point.metadata,
            supporting_data
        )
        
        # Update data point with verification results
        data_point.confidence = verification['confidence_score']
        data_point.trust_level = TrustLevel(verification['trust_level'])
        data_point.verification_count += 1
        
        # Create verification result
        result = VerificationResult(
            data_id=data_id,
            is_verified=verification['is_verified'],
            confidence_score=verification['confidence_score'],
            trust_level=TrustLevel(verification['trust_level']),
            verification_method=verification.get('provider', 'unknown'),
            supporting_sources=verification.get('supporting_evidence', []),
            conflicting_sources=verification.get('contradicting_evidence', []),
            extracted_facts=extracted_facts,
            processing_time_ms=(time.time() - start_time) * 1000
        )
        
        # Cache result
        self.verification_cache[cache_key] = result
        
        # Update stats
        if result.is_verified:
            self.stats['verified_data_points'] += 1
        
        self.stats['trust_distribution'][result.trust_level.value] += 1
        self.stats['verification_time_avg'] = (
            self.stats['verification_time_avg'] * 0.9 + 
            result.processing_time_ms * 0.1
        )
        
        logger.info(f"‚úÖ Verified data point {data_id}: {result.trust_level.value} ({result.confidence_score:.2f})")
        return result
    
    async def _collect_supporting_data(self, data_point: DataPoint) -> List[str]:
        """Collect supporting data from multiple sources"""
        supporting_data = []
        
        # Use configured data sources
        for source_name, source_config in self.config.get('verification_sources', {}).items():
            try:
                source_type = DataSource(source_config.get('type', 'web_api'))
                query = str(data_point.value)
                
                # Limit query length
                if len(query) > 100:
                    query = query[:100]
                
                results = await self.data_collector.collect_from_source(source_type, query, source_config)
                
                for result in results[:3]:  # Max 3 results per source
                    supporting_data.append(result['value'])
                    
            except Exception as e:
                logger.warning(f"Failed to collect from {source_name}: {e}")
        
        return supporting_data
    
    async def cross_reference_data(self, data_id: str) -> List[CrossReference]:
        """Find cross-references for a data point"""
        if data_id not in self.data_points:
            return []
        
        target_data = self.data_points[data_id]
        references = []
        
        # Compare with other data points
        for other_id, other_data in self.data_points.items():
            if other_id == data_id:
                continue
            
            # Calculate similarity
            similarity = await self._calculate_data_similarity(target_data, other_data)
            
            if similarity > 0.7:  # High similarity threshold
                reference = CrossReference(
                    primary_data_id=data_id,
                    reference_data_id=other_id,
                    similarity_score=similarity,
                    relationship_type=self._determine_relationship_type(target_data, other_data),
                    confidence=min(target_data.confidence, other_data.confidence)
                )
                references.append(reference)
        
        return references
    
    async def _calculate_data_similarity(self, data1: DataPoint, data2: DataPoint) -> float:
        """Calculate similarity between two data points"""
        # Type similarity
        if data1.data_type != data2.data_type:
            return 0.0
        
        # Value similarity
        val1_str = str(data1.value).lower()
        val2_str = str(data2.value).lower()
        
        if val1_str == val2_str:
            return 1.0
        
        # Text similarity using AI if available
        if self.fact_verifier.text_model and data1.data_type == DataType.TEXT:
            try:
                embeddings = self.fact_verifier.text_model.encode([val1_str, val2_str])
                similarity = float(np.dot(embeddings[0], embeddings[1]) / 
                                 (np.linalg.norm(embeddings[0]) * np.linalg.norm(embeddings[1])))
                return max(0.0, similarity)
            except Exception:
                pass
        
        # Fallback to simple string similarity
        words1 = set(val1_str.split())
        words2 = set(val2_str.split())
        
        if not words1 and not words2:
            return 1.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def _determine_relationship_type(self, data1: DataPoint, data2: DataPoint) -> str:
        """Determine relationship type between data points"""
        if data1.source == data2.source:
            return "same_source"
        elif abs(data1.timestamp - data2.timestamp) < 300:  # Within 5 minutes
            return "temporal_correlation"
        elif data1.data_type == data2.data_type:
            return "type_similarity"
        else:
            return "content_similarity"
    
    async def _background_processor(self):
        """Background processor for real-time data verification"""
        self.is_processing = True
        
        while self.is_processing:
            try:
                # Check if queue is available
                if not self.processing_queue:
                    await asyncio.sleep(1.0)
                    continue
                
                # Get next data point to process
                data_id = await asyncio.wait_for(self.processing_queue.get(), timeout=1.0)
                
                # Verify the data point
                await self.verify_data_point(data_id)
                
                # Mark task as done
                if self.processing_queue:
                    self.processing_queue.task_done()
                
            except asyncio.TimeoutError:
                # No new data to process
                continue
            except Exception as e:
                logger.error(f"Background processing error: {e}")
                await asyncio.sleep(1)
    
    def get_trusted_data(self, min_trust_level: TrustLevel = TrustLevel.TRUSTED) -> List[DataPoint]:
        """Get data points above minimum trust level"""
        trusted_data = []
        
        trust_order = {
            TrustLevel.VERIFIED: 4,
            TrustLevel.TRUSTED: 3,
            TrustLevel.QUESTIONABLE: 2,
            TrustLevel.UNTRUSTED: 1
        }
        
        min_level_value = trust_order[min_trust_level]
        
        for data_point in self.data_points.values():
            if trust_order[data_point.trust_level] >= min_level_value:
                trusted_data.append(data_point)
        
        # Sort by confidence and recency
        trusted_data.sort(key=lambda d: (d.confidence, d.timestamp), reverse=True)
        
        return trusted_data
    
    def get_data_by_query(self, query: str, data_type: Optional[DataType] = None) -> List[DataPoint]:
        """Search for data points matching a query"""
        matching_data = []
        query_lower = query.lower()
        
        for data_point in self.data_points.values():
            # Type filter
            if data_type and data_point.data_type != data_type:
                continue
            
            # Content matching
            value_str = str(data_point.value).lower()
            if query_lower in value_str:
                matching_data.append(data_point)
        
        # Sort by relevance (confidence and recency)
        matching_data.sort(key=lambda d: (d.confidence, d.timestamp), reverse=True)
        
        return matching_data
    
    def get_fabric_stats(self) -> Dict[str, Any]:
        """Get comprehensive data fabric statistics"""
        total_points = self.stats['total_data_points']
        verified_points = self.stats['verified_data_points']
        
        return {
            'total_data_points': total_points,
            'verified_data_points': verified_points,
            'verified_data': verified_points,  # Fixed: add missing verified_data alias
            'verification_rate': (verified_points / max(1, total_points)) * 100,
            'trust_score': self.stats['trust_distribution'].get('high', 0) / max(1, total_points),  # Fixed: add missing trust_score
            'trust_distribution': dict(self.stats['trust_distribution']),
            'avg_verification_time_ms': self.stats['verification_time_avg'],
            'cache_hit_rate': self.stats['cache_hit_rate'] * 100,
            'active_sources': len(self.config.get('verification_sources', {})),
            'processing_queue_size': self.processing_queue.qsize() if self.processing_queue else 0,
            'cross_references': len(self.cross_references)
        }
    
    async def cleanup_stale_data(self, max_age_hours: int = 24):
        """Remove stale data points"""
        current_time = time.time()
        cutoff_time = current_time - (max_age_hours * 3600)
        
        stale_ids = []
        for data_id, data_point in self.data_points.items():
            if data_point.timestamp < cutoff_time:
                stale_ids.append(data_id)
        
        for data_id in stale_ids:
            del self.data_points[data_id]
            
            # Clean up verification cache
            cache_key = f"verify_{data_id}"
            if cache_key in self.verification_cache:
                del self.verification_cache[cache_key]
        
        logger.info(f"üßπ Cleaned up {len(stale_ids)} stale data points")
        return len(stale_ids)

# Global instance
_data_fabric_ai_instance = None

def get_data_fabric_ai(config: Dict[str, Any] = None) -> RealTimeDataFabricAI:
    """Get global data fabric AI instance"""
    global _data_fabric_ai_instance
    
    if _data_fabric_ai_instance is None:
        default_config = {
            'openai_api_key': None,
            'anthropic_api_key': None,
            'verification_sources': {
                'web_api': {
                    'type': 'web_api',
                    'url': 'https://api.example.com/search'
                },
                'database': {
                    'type': 'database',
                    'database': 'main'
                }
            },
            'trust_threshold': 0.7,
            'max_verification_time_ms': 30000
        }
        
        _data_fabric_ai_instance = RealTimeDataFabricAI(config or default_config)
    
    return _data_fabric_ai_instance

if __name__ == "__main__":
    # Demo the data fabric system
    async def demo():
        print("üåê Real-Time Data Fabric AI Demo")
        print("=" * 50)
        
        fabric = get_data_fabric_ai()
        
        # Ingest test data
        test_data = [
            ("OpenAI was founded in 2015", DataType.TEXT, DataSource.WEB_SCRAPING),
            ("user@example.com", DataType.EMAIL, DataSource.USER_INPUT),
            ("2024-01-15", DataType.DATE, DataSource.DATABASE),
            ("https://example.com", DataType.URL, DataSource.WEB_API),
            ("The capital of France is Paris", DataType.TEXT, DataSource.WEB_SCRAPING)
        ]
        
        print("üì• Ingesting test data...")
        data_ids = []
        
        for value, data_type, source in test_data:
            data_id = await fabric.ingest_data(value, data_type, source)
            data_ids.append(data_id)
            print(f"  ‚úÖ Ingested: {value} ({data_type.value})")
        
        # Wait for background processing
        await asyncio.sleep(2)
        
        print("\nüîç Verification Results:")
        for data_id in data_ids:
            try:
                result = await fabric.verify_data_point(data_id)
                data_point = fabric.data_points[data_id]
                
                print(f"  üìä {data_point.value}")
                print(f"    Trust Level: {result.trust_level.value}")
                print(f"    Confidence: {result.confidence_score:.2f}")
                print(f"    Verification Time: {result.processing_time_ms:.1f}ms")
                print(f"    Facts Extracted: {len(result.extracted_facts)}")
                
                if result.extracted_facts:
                    for fact in result.extracted_facts[:2]:  # Show first 2 facts
                        print(f"      - {fact['entity']} ({fact['type']})")
                print()
                
            except Exception as e:
                print(f"  ‚ùå Verification failed: {e}")
        
        # Test cross-referencing
        print("üîó Cross-Reference Analysis:")
        if data_ids:
            references = await fabric.cross_reference_data(data_ids[0])
            print(f"  Found {len(references)} cross-references for first data point")
            
            for ref in references[:2]:  # Show first 2 references
                other_data = fabric.data_points[ref.reference_data_id]
                print(f"    - {other_data.value} (similarity: {ref.similarity_score:.2f})")
        
        # Test trusted data retrieval
        print("\nüèÜ Trusted Data (Trust Level: TRUSTED or higher):")
        trusted_data = fabric.get_trusted_data(TrustLevel.TRUSTED)
        
        for data_point in trusted_data[:3]:  # Show top 3
            print(f"  ‚úÖ {data_point.value} (confidence: {data_point.confidence:.2f})")
        
        # Test search
        print("\nüîç Search Results for 'example':")
        search_results = fabric.get_data_by_query('example')
        
        for data_point in search_results[:2]:  # Show top 2
            print(f"  üìÑ {data_point.value} ({data_point.trust_level.value})")
        
        # Show statistics
        print("\nüìä Data Fabric Statistics:")
        stats = fabric.get_fabric_stats()
        
        for key, value in stats.items():
            if isinstance(value, float):
                print(f"  {key}: {value:.2f}")
            else:
                print(f"  {key}: {value}")
        
        print("\n‚úÖ Data fabric demo complete!")
        print("üèÜ AI-powered trust scoring and real-time verification!")
    
    asyncio.run(demo())