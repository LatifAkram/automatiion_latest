#!/usr/bin/env python3
"""
Built-in AI Processor - 100% Dependency-Free
============================================

Complete AI/ML processing system using only Python standard library.
Provides intelligent text processing, pattern recognition, and decision making.
"""

import re
import math
import json
import random
import statistics
from typing import Dict, List, Any, Optional, Tuple
from collections import Counter, defaultdict
from dataclasses import dataclass
import hashlib
import time

@dataclass
class AIResponse:
    """AI processing response"""
    confidence: float
    result: Any
    reasoning: str
    processing_time: float

class TextProcessor:
    """Advanced text processing and analysis"""
    
    def __init__(self):
        self.common_words = {
            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for',
            'of', 'with', 'by', 'from', 'up', 'about', 'into', 'through', 'during',
            'before', 'after', 'above', 'below', 'between', 'among', 'is', 'are',
            'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does',
            'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can'
        }
        
        self.sentiment_positive = {
            'good', 'great', 'excellent', 'amazing', 'wonderful', 'fantastic',
            'awesome', 'love', 'like', 'enjoy', 'happy', 'pleased', 'satisfied',
            'perfect', 'best', 'brilliant', 'outstanding', 'superb', 'magnificent'
        }
        
        self.sentiment_negative = {
            'bad', 'terrible', 'awful', 'horrible', 'hate', 'dislike', 'angry',
            'frustrated', 'disappointed', 'worst', 'poor', 'useless', 'broken',
            'failed', 'error', 'problem', 'issue', 'wrong', 'difficult'
        }
    
    def tokenize(self, text: str) -> List[str]:
        """Tokenize text into words"""
        # Remove punctuation and convert to lowercase
        cleaned = re.sub(r'[^\w\s]', ' ', text.lower())
        return [word for word in cleaned.split() if word]
    
    def extract_keywords(self, text: str, top_k: int = 10) -> List[Tuple[str, float]]:
        """Extract keywords with TF-IDF-like scoring"""
        tokens = self.tokenize(text)
        
        # Remove common words
        filtered_tokens = [token for token in tokens if token not in self.common_words]
        
        # Calculate term frequency
        term_freq = Counter(filtered_tokens)
        total_terms = len(filtered_tokens)
        
        # Simple TF-IDF approximation
        keyword_scores = {}
        for term, freq in term_freq.items():
            tf = freq / total_terms
            # Simple IDF approximation (longer words get higher scores)
            idf = math.log(len(term) + 1)
            keyword_scores[term] = tf * idf
        
        # Return top keywords
        return sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
    
    def analyze_sentiment(self, text: str) -> Tuple[str, float]:
        """Analyze sentiment of text"""
        tokens = self.tokenize(text)
        
        positive_score = sum(1 for token in tokens if token in self.sentiment_positive)
        negative_score = sum(1 for token in tokens if token in self.sentiment_negative)
        
        if positive_score > negative_score:
            sentiment = "positive"
            confidence = min(0.9, (positive_score - negative_score) / len(tokens) * 10)
        elif negative_score > positive_score:
            sentiment = "negative"
            confidence = min(0.9, (negative_score - positive_score) / len(tokens) * 10)
        else:
            sentiment = "neutral"
            confidence = 0.5
        
        return sentiment, confidence
    
    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """Extract named entities using pattern matching"""
        entities = {
            'emails': re.findall(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', text),
            'urls': re.findall(r'https?://(?:[-\w.])+(?:[:\d]+)?(?:/(?:[\w/_.])*(?:\?(?:[\w&=%.])*)?(?:#(?:\w*))?)?', text),
            'phone_numbers': re.findall(r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b', text),
            'dates': re.findall(r'\b\d{1,2}[-/]\d{1,2}[-/]\d{2,4}\b', text),
            'numbers': re.findall(r'\b\d+(?:\.\d+)?\b', text),
            'capitalized_words': re.findall(r'\b[A-Z][a-z]+\b', text)
        }
        
        return entities
    
    def calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate text similarity using Jaccard coefficient"""
        tokens1 = set(self.tokenize(text1))
        tokens2 = set(self.tokenize(text2))
        
        if not tokens1 and not tokens2:
            return 1.0
        
        intersection = len(tokens1.intersection(tokens2))
        union = len(tokens1.union(tokens2))
        
        return intersection / union if union > 0 else 0.0

class PatternRecognizer:
    """Pattern recognition and classification"""
    
    def __init__(self):
        self.learned_patterns = {}
        self.classification_rules = {}
    
    def learn_pattern(self, pattern_name: str, examples: List[str]):
        """Learn a pattern from examples"""
        # Extract common features from examples
        features = []
        for example in examples:
            features.append(self._extract_features(example))
        
        # Find common patterns
        common_features = self._find_common_features(features)
        self.learned_patterns[pattern_name] = common_features
    
    def _extract_features(self, text: str) -> Dict[str, Any]:
        """Extract features from text"""
        return {
            'length': len(text),
            'word_count': len(text.split()),
            'has_numbers': bool(re.search(r'\d', text)),
            'has_uppercase': bool(re.search(r'[A-Z]', text)),
            'has_special_chars': bool(re.search(r'[!@#$%^&*(),.?":{}|<>]', text)),
            'starts_with_capital': text[0].isupper() if text else False,
            'ends_with_punctuation': text[-1] in '.!?' if text else False,
            'avg_word_length': statistics.mean([len(word) for word in text.split()]) if text.split() else 0
        }
    
    def _find_common_features(self, features_list: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Find common features across examples"""
        if not features_list:
            return {}
        
        common = {}
        for key in features_list[0]:
            values = [f[key] for f in features_list]
            
            if isinstance(values[0], bool):
                # For boolean features, use majority vote
                common[key] = sum(values) > len(values) / 2
            elif isinstance(values[0], (int, float)):
                # For numeric features, use average with tolerance
                common[key] = {
                    'mean': statistics.mean(values),
                    'std': statistics.stdev(values) if len(values) > 1 else 0,
                    'min': min(values),
                    'max': max(values)
                }
        
        return common
    
    def classify(self, text: str) -> Tuple[str, float]:
        """Classify text against learned patterns"""
        if not self.learned_patterns:
            return "unknown", 0.0
        
        features = self._extract_features(text)
        best_match = None
        best_score = 0.0
        
        for pattern_name, pattern_features in self.learned_patterns.items():
            score = self._calculate_pattern_match(features, pattern_features)
            if score > best_score:
                best_score = score
                best_match = pattern_name
        
        return best_match or "unknown", best_score
    
    def _calculate_pattern_match(self, features: Dict[str, Any], pattern: Dict[str, Any]) -> float:
        """Calculate how well features match a pattern"""
        matches = 0
        total = 0
        
        for key, pattern_value in pattern.items():
            if key not in features:
                continue
            
            total += 1
            feature_value = features[key]
            
            if isinstance(pattern_value, bool):
                if feature_value == pattern_value:
                    matches += 1
            elif isinstance(pattern_value, dict) and 'mean' in pattern_value:
                # Numeric feature with statistics
                mean = pattern_value['mean']
                std = pattern_value['std']
                tolerance = std + 0.1  # Add small tolerance
                
                if abs(feature_value - mean) <= tolerance:
                    matches += 1
        
        return matches / total if total > 0 else 0.0

class DecisionEngine:
    """Intelligent decision making engine"""
    
    def __init__(self):
        self.decision_tree = {}
        self.rules = []
        self.weights = {}
    
    def add_rule(self, condition: str, action: str, weight: float = 1.0):
        """Add decision rule"""
        self.rules.append({
            'condition': condition,
            'action': action,
            'weight': weight
        })
    
    def evaluate_condition(self, condition: str, context: Dict[str, Any]) -> bool:
        """Evaluate a condition against context"""
        try:
            # Simple condition evaluation
            # Replace variables in condition with context values
            for key, value in context.items():
                condition = condition.replace(f'${key}', str(value))
            
            # Evaluate simple expressions
            if '>' in condition:
                left, right = condition.split('>')
                return float(left.strip()) > float(right.strip())
            elif '<' in condition:
                left, right = condition.split('<')
                return float(left.strip()) < float(right.strip())
            elif '==' in condition:
                left, right = condition.split('==')
                return left.strip() == right.strip()
            elif 'contains' in condition:
                left, right = condition.split('contains')
                return right.strip().strip('"\'') in left.strip()
            
            return False
        except:
            return False
    
    def make_decision(self, context: Dict[str, Any]) -> Tuple[str, float, str]:
        """Make decision based on rules and context"""
        applicable_rules = []
        
        for rule in self.rules:
            if self.evaluate_condition(rule['condition'], context):
                applicable_rules.append(rule)
        
        if not applicable_rules:
            return "no_action", 0.0, "No applicable rules found"
        
        # Weight rules and select best action
        action_scores = defaultdict(float)
        for rule in applicable_rules:
            action_scores[rule['action']] += rule['weight']
        
        best_action = max(action_scores, key=action_scores.get)
        confidence = min(1.0, action_scores[best_action] / len(self.rules))
        
        reasoning = f"Applied {len(applicable_rules)} rules, best action: {best_action}"
        
        return best_action, confidence, reasoning

class BuiltinAIProcessor:
    """Main AI processor combining all capabilities"""
    
    def __init__(self):
        self.text_processor = TextProcessor()
        self.pattern_recognizer = PatternRecognizer()
        self.decision_engine = DecisionEngine()
        self.memory = {}
        
        # Setup default rules
        self._setup_default_rules()
    
    def _setup_default_rules(self):
        """Setup default decision rules"""
        self.decision_engine.add_rule(
            "$confidence > 0.8",
            "high_confidence_action",
            2.0
        )
        
        self.decision_engine.add_rule(
            "$sentiment == positive",
            "positive_response",
            1.5
        )
        
        self.decision_engine.add_rule(
            "$error_count > 3",
            "error_handling",
            3.0
        )
    
    def process_text(self, text: str, task: str = "analyze") -> AIResponse:
        """Process text with AI capabilities"""
        start_time = time.time()
        
        try:
            if task == "analyze":
                result = self._analyze_text(text)
            elif task == "classify":
                result = self._classify_text(text)
            elif task == "extract":
                result = self._extract_information(text)
            elif task == "decide":
                result = self._make_decision(text)
            else:
                result = {"error": f"Unknown task: {task}"}
            
            processing_time = time.time() - start_time
            confidence = result.get('confidence', 0.8)
            reasoning = result.get('reasoning', f"Processed with task: {task}")
            
            return AIResponse(
                confidence=confidence,
                result=result,
                reasoning=reasoning,
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = time.time() - start_time
            return AIResponse(
                confidence=0.0,
                result={"error": str(e)},
                reasoning=f"Processing failed: {e}",
                processing_time=processing_time
            )
    
    def _analyze_text(self, text: str) -> Dict[str, Any]:
        """Comprehensive text analysis"""
        keywords = self.text_processor.extract_keywords(text)
        sentiment, sentiment_confidence = self.text_processor.analyze_sentiment(text)
        entities = self.text_processor.extract_entities(text)
        
        return {
            "keywords": keywords,
            "sentiment": sentiment,
            "sentiment_confidence": sentiment_confidence,
            "entities": entities,
            "word_count": len(text.split()),
            "character_count": len(text),
            "confidence": sentiment_confidence,
            "reasoning": "Performed comprehensive text analysis"
        }
    
    def _classify_text(self, text: str) -> Dict[str, Any]:
        """Classify text using pattern recognition"""
        classification, confidence = self.pattern_recognizer.classify(text)
        
        return {
            "classification": classification,
            "confidence": confidence,
            "reasoning": f"Classified as {classification} with {confidence:.2f} confidence"
        }
    
    def _extract_information(self, text: str) -> Dict[str, Any]:
        """Extract structured information from text"""
        entities = self.text_processor.extract_entities(text)
        keywords = self.text_processor.extract_keywords(text, top_k=5)
        
        return {
            "entities": entities,
            "keywords": [kw[0] for kw in keywords],
            "confidence": 0.7,
            "reasoning": "Extracted entities and keywords using pattern matching"
        }
    
    def _make_decision(self, text: str) -> Dict[str, Any]:
        """Make intelligent decision based on text"""
        analysis = self._analyze_text(text)
        
        context = {
            "sentiment": analysis["sentiment"],
            "confidence": analysis["sentiment_confidence"],
            "word_count": analysis["word_count"],
            "error_count": len([entity for entity in analysis["entities"]["capitalized_words"] 
                              if "error" in entity.lower() or "fail" in entity.lower()])
        }
        
        action, confidence, reasoning = self.decision_engine.make_decision(context)
        
        return {
            "action": action,
            "confidence": confidence,
            "reasoning": reasoning,
            "context": context
        }
    
    def train_pattern(self, pattern_name: str, examples: List[str]):
        """Train the AI on new patterns"""
        self.pattern_recognizer.learn_pattern(pattern_name, examples)
    
    def add_decision_rule(self, condition: str, action: str, weight: float = 1.0):
        """Add new decision rule"""
        self.decision_engine.add_rule(condition, action, weight)
    
    def remember(self, key: str, value: Any):
        """Store information in memory"""
        self.memory[key] = value
    
    def recall(self, key: str) -> Any:
        """Retrieve information from memory"""
        return self.memory.get(key)
    
    def make_decision(self, options: List[str], context: Dict[str, Any]) -> AIResponse:
        """Make a decision from given options based on context"""
        start_time = time.time()
        
        if not options:
            return AIResponse(
                result={'choice': None, 'confidence': 0.0, 'reasoning': 'No options provided'},
                confidence=0.0,
                reasoning='No options provided',
                processing_time=time.time() - start_time
            )
        
        # Use decision engine to evaluate options
        context_text = json.dumps(context) if context else ""
        decision_result = self.decision_engine.make_decision(context_text)
        
        # Map decision to available options
        best_option = None
        best_score = 0.0
        reasoning = "Rule-based decision making"
        
        # Simple keyword matching to select best option
        for option in options:
            score = 0.0
            option_lower = option.lower()
            
            # Score based on context keywords
            if context:
                context_str = str(context).lower()
                common_words = set(option_lower.split()) & set(context_str.split())
                score += len(common_words) * 0.2
            
            # Score based on option characteristics
            if 'error' in context_str and any(word in option_lower for word in ['fix', 'repair', 'resolve']):
                score += 0.5
            elif 'success' in context_str and any(word in option_lower for word in ['continue', 'proceed', 'next']):
                score += 0.5
            elif any(word in option_lower for word in ['default', 'standard', 'normal']):
                score += 0.3
            
            if score > best_score:
                best_score = score
                best_option = option
                reasoning = f"Selected '{option}' based on context analysis (score: {score:.2f})"
        
        # If no clear winner, pick first option
        if not best_option:
            best_option = options[0]
            reasoning = "Default selection (first option)"
            best_score = 0.5
        
        confidence = min(0.95, max(0.3, best_score))
        
        return AIResponse(
            result={
                'choice': best_option,
                'confidence': confidence,
                'reasoning': reasoning,
                'options_evaluated': len(options),
                'decision_method': 'rule_based'
            },
            confidence=confidence,
            reasoning=reasoning,
            processing_time=time.time() - start_time
        )

# Global AI processor instance
ai_processor = BuiltinAIProcessor()

def process_with_ai(text: str, task: str = "analyze") -> AIResponse:
    """Quick access to AI processing"""
    return ai_processor.process_text(text, task)

def train_ai_pattern(pattern_name: str, examples: List[str]):
    """Train AI on new patterns"""
    ai_processor.train_pattern(pattern_name, examples)

if __name__ == "__main__":
    # Demo the built-in AI processor
    print("üß† Built-in AI Processor Demo")
    print("=" * 40)
    
    processor = BuiltinAIProcessor()
    
    # Test text analysis
    test_text = "This is an amazing product! I love how it works perfectly. Contact us at info@example.com or call 555-123-4567."
    
    print("üìù Text Analysis:")
    result = processor.process_text(test_text, "analyze")
    print(f"  Confidence: {result.confidence:.2f}")
    print(f"  Sentiment: {result.result['sentiment']}")
    print(f"  Keywords: {[kw[0] for kw in result.result['keywords'][:3]]}")
    print(f"  Entities found: {sum(len(v) for v in result.result['entities'].values())}")
    print(f"  Processing time: {result.processing_time*1000:.1f}ms")
    
    # Test pattern learning
    print("\nüéØ Pattern Learning:")
    email_examples = [
        "Please contact support@company.com for help",
        "Send your resume to hr@startup.io",
        "For billing questions, email billing@service.net"
    ]
    
    processor.train_pattern("support_request", email_examples)
    
    test_classification = processor.process_text("Email admin@website.org for assistance", "classify")
    print(f"  Classification: {test_classification.result['classification']}")
    print(f"  Confidence: {test_classification.result['confidence']:.2f}")
    
    # Test decision making
    print("\nü§î Decision Making:")
    decision_result = processor.process_text("There are multiple errors in the system", "decide")
    print(f"  Recommended action: {decision_result.result['action']}")
    print(f"  Confidence: {decision_result.result['confidence']:.2f}")
    print(f"  Reasoning: {decision_result.result['reasoning']}")
    
    print("\n‚úÖ Built-in AI processor working perfectly!")
    print("üß† Intelligence without external ML libraries!")
    print("üéØ No transformers or torch dependencies required!")